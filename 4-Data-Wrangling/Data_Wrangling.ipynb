{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap Data Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Area\n",
    "\n",
    "San Jose, CA, United States\n",
    "\n",
    "- https://mapzen.com/data/metro-extracts/ (Metro Extract has been discontinued as of Feb 1st, 2018)\n",
    "- https://gist.github.com/carlward/54ec1c91b62a5f911c42#file-sample_project-md (Sample SQL project)\n",
    "- https://docs.python.org/3/library/sqlite3.html (Python documentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems Encountered in the Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "from collections import defaultdict\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first run the code to find out how many different types of tags are there and the count of each tag.\n",
    "\n",
    "It helps to provide an overview of the amount of data in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bounds': 1,\n",
      " 'member': 22273,\n",
      " 'nd': 2217224,\n",
      " 'node': 1898718,\n",
      " 'osm': 1,\n",
      " 'relation': 2642,\n",
      " 'tag': 780009,\n",
      " 'way': 250204}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The code below is to find out how many types of tags are there and the number of each tag.\n",
    "'''\n",
    "\n",
    "def count_tags(filename):\n",
    "    tags = {}\n",
    "    for event, element in ET.iterparse(filename):\n",
    "        if element.tag not in tags.keys():\n",
    "            tags[element.tag] = 1\n",
    "        else:\n",
    "            tags[element.tag] += 1\n",
    "    return tags\n",
    "\n",
    "def test():\n",
    "\n",
    "    tags = count_tags('san-jose_california.osm')\n",
    "    pprint.pprint(tags)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I check for any errors in the tags by classifying them into tags with:\n",
    "\n",
    "- only lowercase\n",
    "- lowercase and colon\n",
    "- problematic characters\n",
    "- others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': 522227, 'lower_colon': 235222, 'other': 22560, 'problemchars': 0}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The code below allows you to check the k value for each tag.\n",
    "By classifying the tagss into few categories:\n",
    "1. \"lower\": valid tags containing only lowercase letters\n",
    "2. \"lower_colon\": valid tags with a colon in the names\n",
    "3. \"problemchars\": tags with problematic characters\n",
    "4. \"other\": other tags that don't fall into the 3 categories above\n",
    "'''\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        k = element.attrib['k']\n",
    "        if re.search(lower,k):\n",
    "            keys[\"lower\"] += 1\n",
    "        elif re.search(lower_colon,k):\n",
    "            keys[\"lower_colon\"] += 1\n",
    "        elif re.search(problemchars,k):\n",
    "            keys[\"problemchars\"] += 1\n",
    "        else:\n",
    "            keys[\"other\"] += 1\n",
    "    return keys\n",
    "\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "    return keys\n",
    "\n",
    "def test():\n",
    "    keys = process_map('san-jose_california.osm')\n",
    "    pprint.pprint(keys)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auditng Street Names\n",
    "\n",
    "I construct of a list of common expected street type such as \"Street\", \"Avenue\" etc.\n",
    "\n",
    "Then, I list out all the street type not in the expected street type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0.1': set(['Ala 680 PM 0.1']),\n",
      " '1': set(['Prospect Rd #1', 'Stewart Drive Suite #1']),\n",
      " '114': set(['West Evelyn Avenue Suite #114']),\n",
      " '201': set(['Great America Pkwy Ste 201']),\n",
      " '4A': set(['Saratoga Avenue Bldg 4A']),\n",
      " '6': set(['Martin Avenue #6', 'Pruneridge Ave #6']),\n",
      " '7.1': set(['Hwy 17 PM 7.1']),\n",
      " '81': set(['Concourse Dr #81']),\n",
      " 'Alameda': set(['The Alameda']),\n",
      " 'Alley': set(['Fountain Alley']),\n",
      " 'Ave': set(['1425 E Dunne Ave',\n",
      "             'Blake Ave',\n",
      "             'Cabrillo Ave',\n",
      "             'Cherry Ave',\n",
      "             'E Duane Ave',\n",
      "             'Foxworthy Ave',\n",
      "             'Greenbriar Ave',\n",
      "             'Hillsdale Ave',\n",
      "             'Hollenbeck Ave',\n",
      "             'Meridian Ave',\n",
      "             'N Blaney Ave',\n",
      "             'Saratoga Ave',\n",
      "             'Seaboard Ave',\n",
      "             'The Alameda Ave',\n",
      "             'W Washington Ave',\n",
      "             'Walsh Ave',\n",
      "             'Westfield Ave']),\n",
      " 'Barcelona': set(['Calle de Barcelona']),\n",
      " 'Bascom': set(['S. Bascom']),\n",
      " 'Bellomy': set(['Bellomy']),\n",
      " 'Blvd': set(['Los Gatos Blvd',\n",
      "              'McCarthy Blvd',\n",
      "              'Mission College Blvd',\n",
      "              'N McCarthy Blvd',\n",
      "              'Palm Valley Blvd',\n",
      "              'Santa Teresa Blvd',\n",
      "              'Stevens Creek Blvd']),\n",
      " 'Blvd.': set(['Los Gatos Blvd.']),\n",
      " 'Boulvevard': set(['Los Gatos Boulvevard']),\n",
      " 'Broadway': set(['Broadway']),\n",
      " 'CA': set(['Zanker Rd., San Jose, CA', 'Zanker Road, San Jose, CA']),\n",
      " 'Cir': set(['Celadon Cir']),\n",
      " 'Ct': set(['Perivale Ct']),\n",
      " 'Dr': set(['1350 S Park Victoria Dr',\n",
      "            '1490 S Park Victoria Dr',\n",
      "            'Fountain Oaks Dr',\n",
      "            'Linwood Dr',\n",
      "            'Minto Dr',\n",
      "            'Oakmead Village Dr',\n",
      "            'Samaritan Dr']),\n",
      " 'East': set(['Park Circle East', 'Rio Robles East', 'Vanderbilt Court East']),\n",
      " 'Esquela': set(['Camina Esquela']),\n",
      " 'Expressway': set(['Almaden Expressway',\n",
      "                    'Central Expressway',\n",
      "                    'East Capitol Expressway',\n",
      "                    'Lawrence Expressway',\n",
      "                    'Montague Expressway',\n",
      "                    'San Tomas Expressway',\n",
      "                    'Southwest Expressway',\n",
      "                    'West Capitol Expressway']),\n",
      " 'Flores': set(['Terreno De Flores']),\n",
      " 'Franklin': set(['Franklin']),\n",
      " 'Hamilton': set(['Mount Hamilton']),\n",
      " 'Highway': set(['Monterey Highway',\n",
      "                 'Old Bayshore Highway',\n",
      "                 'Old Santa Cruz Highway']),\n",
      " 'Hill': set(['Blossom Hill']),\n",
      " 'Hwy': set(['Monterey Hwy']),\n",
      " 'Ln': set(['Barber Ln', 'Branham Ln', 'Gaundabert Ln']),\n",
      " 'Loop': set(['Infinite Loop', 'Village View Loop']),\n",
      " 'Luna': set(['Calle de Luna']),\n",
      " 'Madrid': set(['Corte de Madrid']),\n",
      " 'Mall': set(['Franklin Mall']),\n",
      " 'Marino': set(['Via San Marino']),\n",
      " u'Monta\\xf1a': set([u'Vista Monta\\xf1a']),\n",
      " 'Napoli': set(['Via Napoli']),\n",
      " 'Oaks': set(['North Fair Oaks']),\n",
      " 'Oro': set(['Via del Oro']),\n",
      " 'Palamos': set(['Via Palamos']),\n",
      " 'Paviso': set(['Via Paviso']),\n",
      " 'Plaza': set(['Portal Plaza', 'Rivermark Plaza']),\n",
      " 'Portofino': set(['Via Portofino']),\n",
      " 'Presada': set(['Paseo Presada']),\n",
      " 'Rd': set(['Berryessa Rd',\n",
      "            'Homestead Rd',\n",
      "            'Mt Hamilton Rd',\n",
      "            'Mt. Hamilton Rd',\n",
      "            'Quimby Rd',\n",
      "            'San Antonio Valley Rd',\n",
      "            'Saratoga Los Gatos Rd',\n",
      "            'Silver Creek Valley Rd',\n",
      "            'Wolfe Rd']),\n",
      " 'Real': set(['E El Camino Real',\n",
      "              'East El Camino Real',\n",
      "              'El Camino Real',\n",
      "              'West El Camino Real']),\n",
      " 'Row': set(['Santana Row']),\n",
      " 'Saratoga': set(['El Paseo de Saratoga']),\n",
      " 'Seville': set(['Corte de Seville']),\n",
      " 'Sorrento': set(['Via Sorrento']),\n",
      " 'St': set(['Casa Verde St', 'Monroe St', 'N 5th St']),\n",
      " 'Volante': set(['Via Volante']),\n",
      " 'Walk': set(['Paseo de San Antonio Walk']),\n",
      " 'West': set(['Park Circle West', 'Vanderbilt Court West']),\n",
      " 'Winchester': set(['Winchester']),\n",
      " 'ave': set(['wilcox ave']),\n",
      " 'court': set(['Cortona court']),\n",
      " 'robles': set(['rio robles']),\n",
      " 'street': set(['N 1st street']),\n",
      " 'yes': set(['yes'])}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The code below lists out all the street types not in the expected list.\n",
    "'''\n",
    "OSMFILE = \"san-jose_california.osm\"\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\", \"Circle\", \"Terrace\", \"Way\"]\n",
    "\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n",
    "st_types = audit(OSMFILE)\n",
    "\n",
    "def test():    \n",
    "    pprint.pprint(dict(st_types))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It can be seen from the output above that there are a lot of inconsistencies and error in street type.\n",
    "\n",
    "Few examples are:\n",
    "- \"St\" (overabbreviated)\n",
    "- \"4A\" (referring to unit number)\n",
    "- \"Alameda\" (building name)\n",
    "- \"CA\" (state name)\n",
    "\n",
    "While it will be difficult to clean most inconsistencies in street type, the overabbreviated ones are easier to identify and correct. A mapping list is written by pairing the overabbreviated name to the full street type name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Martin Avenue #6 => Martin Avenue #6\n",
      "Pruneridge Ave #6 => Pruneridge Ave #6\n",
      "Concourse Dr #81 => Concourse Dr #81\n",
      "Winchester => Winchester\n",
      "Gaundabert Ln => Gaundabert Ln\n",
      "Barber Ln => Barber Ln\n",
      "Branham Ln => Branham Ln\n",
      "Park Circle West => Park Circle West\n",
      "Vanderbilt Court West => Vanderbilt Court West\n",
      "Wolfe Rd => Wolfe Road\n",
      "Mt Hamilton Rd => Mt Hamilton Road\n",
      "Berryessa Rd => Berryessa Road\n",
      "Saratoga Los Gatos Rd => Saratoga Los Gatos Road\n",
      "Quimby Rd => Quimby Road\n",
      "San Antonio Valley Rd => San Antonio Valley Road\n",
      "Homestead Rd => Homestead Road\n",
      "Mt. Hamilton Rd => Mt. Hamilton Road\n",
      "Silver Creek Valley Rd => Silver Creek Valley Road\n",
      "West Evelyn Avenue Suite #114 => West Evelyn Avenue Suite #114\n",
      "Hwy 17 PM 7.1 => Hwy 17 PM 7.1\n",
      "Blossom Hill => Blossom Hill\n",
      "wilcox ave => wilcox ave\n",
      "North Fair Oaks => North Fair Oaks\n",
      "Vanderbilt Court East => Vanderbilt Court East\n",
      "Park Circle East => Park Circle East\n",
      "Rio Robles East => Rio Robles East\n",
      "The Alameda => The Alameda\n",
      "yes => yes\n",
      "Monterey Highway => Monterey Highway\n",
      "Old Santa Cruz Highway => Old Santa Cruz Highway\n",
      "Old Bayshore Highway => Old Bayshore Highway\n",
      "El Camino Real => El Camino Real\n",
      "E El Camino Real => E El Camino Real\n",
      "West El Camino Real => West El Camino Real\n",
      "East El Camino Real => East El Camino Real\n",
      "San Tomas Expressway => San Tomas Expressway\n",
      "East Capitol Expressway => East Capitol Expressway\n",
      "Montague Expressway => Montague Expressway\n",
      "West Capitol Expressway => West Capitol Expressway\n",
      "Central Expressway => Central Expressway\n",
      "Almaden Expressway => Almaden Expressway\n",
      "Lawrence Expressway => Lawrence Expressway\n",
      "Southwest Expressway => Southwest Expressway\n",
      "Cortona court => Cortona court\n",
      "Via Paviso => Via Paviso\n",
      "Vista Montaña => Vista Montaña\n",
      "Stewart Drive Suite #1 => Stewart Drive Suite #1\n",
      "Prospect Rd #1 => Prospect Rd #1\n",
      "Via del Oro => Via del Oro\n",
      "Terreno De Flores => Terreno De Flores\n",
      "Mount Hamilton => Mount Hamilton\n",
      "Via San Marino => Via San Marino\n",
      "Monterey Hwy => Monterey Hwy\n",
      "Via Volante => Via Volante\n",
      "S. Bascom => S. Bascom\n",
      "Oakmead Village Dr => Oakmead Village Drive\n",
      "Fountain Oaks Dr => Fountain Oaks Drive\n",
      "Minto Dr => Minto Drive\n",
      "1350 S Park Victoria Dr => 1350 S Park Victoria Drive\n",
      "Linwood Dr => Linwood Drive\n",
      "1490 S Park Victoria Dr => 1490 S Park Victoria Drive\n",
      "Samaritan Dr => Samaritan Drive\n",
      "Great America Pkwy Ste 201 => Great America Pkwy Ste 201\n",
      "Camina Esquela => Camina Esquela\n",
      "Ala 680 PM 0.1 => Ala 680 PM 0.1\n",
      "Bellomy => Bellomy\n",
      "Via Napoli => Via Napoli\n",
      "El Paseo de Saratoga => El Paseo de Saratoga\n",
      "Zanker Rd., San Jose, CA => Zanker Rd., San Jose, CA\n",
      "Zanker Road, San Jose, CA => Zanker Road, San Jose, CA\n",
      "Portal Plaza => Portal Plaza\n",
      "Rivermark Plaza => Rivermark Plaza\n",
      "Calle de Barcelona => Calle de Barcelona\n",
      "N 5th St => N 5th Street\n",
      "Monroe St => Monroe Street\n",
      "Casa Verde St => Casa Verde Street\n",
      "Celadon Cir => Celadon Cir\n",
      "Franklin Mall => Franklin Mall\n",
      "Franklin => Franklin\n",
      "Broadway => Broadway\n",
      "Via Palamos => Via Palamos\n",
      "Corte de Seville => Corte de Seville\n",
      "Paseo Presada => Paseo Presada\n",
      "Village View Loop => Village View Loop\n",
      "Infinite Loop => Infinite Loop\n",
      "Saratoga Avenue Bldg 4A => Saratoga Avenue Bldg 4A\n",
      "Via Sorrento => Via Sorrento\n",
      "Los Gatos Boulvevard => Los Gatos Boulvevard\n",
      "Corte de Madrid => Corte de Madrid\n",
      "Via Portofino => Via Portofino\n",
      "Fountain Alley => Fountain Alley\n",
      "Paseo de San Antonio Walk => Paseo de San Antonio Walk\n",
      "Calle de Luna => Calle de Luna\n",
      "N 1st street => N 1st street\n",
      "rio robles => rio robles\n",
      "Los Gatos Blvd => Los Gatos Boulevard\n",
      "Mission College Blvd => Mission College Boulevard\n",
      "Stevens Creek Blvd => Stevens Creek Boulevard\n",
      "Santa Teresa Blvd => Santa Teresa Boulevard\n",
      "Palm Valley Blvd => Palm Valley Boulevard\n",
      "N McCarthy Blvd => N McCarthy Boulevard\n",
      "McCarthy Blvd => McCarthy Boulevard\n",
      "Cherry Ave => Cherry Avenue\n",
      "Saratoga Ave => Saratoga Avenue\n",
      "Greenbriar Ave => Greenbriar Avenue\n",
      "Blake Ave => Blake Avenue\n",
      "Foxworthy Ave => Foxworthy Avenue\n",
      "Hillsdale Ave => Hillsdale Avenue\n",
      "N Blaney Ave => N Blaney Avenue\n",
      "Meridian Ave => Meridian Avenue\n",
      "Westfield Ave => Westfield Avenue\n",
      "The Alameda Ave => The Alameda Avenue\n",
      "Seaboard Ave => Seaboard Avenue\n",
      "Walsh Ave => Walsh Avenue\n",
      "E Duane Ave => E Duane Avenue\n",
      "W Washington Ave => W Washington Avenue\n",
      "1425 E Dunne Ave => 1425 E Dunne Avenue\n",
      "Cabrillo Ave => Cabrillo Avenue\n",
      "Hollenbeck Ave => Hollenbeck Avenue\n",
      "Santana Row => Santana Row\n",
      "Los Gatos Blvd. => Los Gatos Blvd.\n",
      "Perivale Ct => Perivale Ct\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The code below updates the unexpected street types listed in the mapping list\n",
    "while keeping others unchanged.\n",
    "'''\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Rd.\": \"Road\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Blvd\": \"Boulevard\",\n",
    "            \"Dr\": \"Drive\",\n",
    "            \"Rd\": \"Road\"\n",
    "            }\n",
    "\n",
    "def update_name(name, mapping):\n",
    "    m = street_type_re.search(name)\n",
    "    if m.group() not in expected:\n",
    "        if m.group() in mapping.keys():\n",
    "            name = re.sub(m.group(), mapping[m.group()], name)\n",
    "    return name\n",
    "\n",
    "def test():\n",
    "    for st_type, ways in st_types.iteritems():\n",
    "        for name in ways:\n",
    "            better_name = update_name(name, mapping)\n",
    "            print name, \"=>\", better_name\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auditng Zip Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some results have been abbreviated\n",
      "{'94': set(['94024',\n",
      "            '94084',\n",
      "            '94085',\n",
      "            '94085-3010',\n",
      "            '94086',\n",
      "            '94086-6406',\n",
      "            '94087',\n",
      "            u'94087\\u200e',\n",
      "            '94088-3453',\n",
      "            '94088-3707',\n",
      "            '94089',\n",
      "            '94089-2701',\n",
      "            '94538',\n",
      "            '94807']),\n",
      " '95': set(['95002',\n",
      "            '95008',\n",
      "            '95013',\n",
      "            '95014',\n",
      "            '95014-0200',\n",
      "            '95014-0202',\n",
      "            '95014-0236',\n",
      "            '95134',\n",
      "            '95134-1358',\n",
      "            '95135',\n",
      "            '95136',\n",
      "            '95148',\n",
      "            '95191',\n",
      "            '95914']),\n",
      " 'CA': set(['CA 94035',\n",
      "            'CA 94085',\n",
      "            'CA 94086',\n",
      "            'CA 95054',\n",
      "            'CA 95110',\n",
      "            'CA 95116']),\n",
      " 'CU': set(['CUPERTINO'])}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This code checks for zipcode whether they begin with '94' or '95' or something else\n",
    "'''\n",
    "OSMFILE = \"san-jose_california.osm\"\n",
    "zip_type_re = re.compile(r'\\d{5}$')\n",
    "\n",
    "def audit_ziptype(zip_types, zipcode):\n",
    "    if zipcode[0:2] != 95:\n",
    "        zip_types[zipcode[0:2]].add(zipcode)\n",
    "    elif zipcode[0:2] != 94:\n",
    "        zip_types[zipcode[0:2]].add(zipcode)\n",
    "        \n",
    "def is_zipcode(elem):\n",
    "    return (elem.attrib['k'] == \"addr:postcode\")\n",
    "\n",
    "def audit_zip(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    zip_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_zipcode(tag):\n",
    "                    audit_ziptype(zip_types,tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return zip_types\n",
    "\n",
    "zip_print = audit_zip(OSMFILE)\n",
    "\n",
    "def test():    \n",
    "    pprint.pprint(dict(zip_print))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "update the zip code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some results have been abbreviated\n",
      "CA 95054 => 95054\n",
      "CA 94035 => 94035\n",
      "CA 95110 => 95110\n",
      "CA 95116 => 95116\n",
      "CA 94085 => 94085\n",
      "CA 94086 => 94086\n",
      "95014-1899 => 95014\n",
      "95014-5398 => 95014\n",
      "95014-3456 => 95014\n",
      "95032-2502 => 95032\n",
      "94087 => 94087\n",
      "94024 => 94024\n",
      "94087‎ => 94087‎\n",
      "94089-2701 => 94089\n",
      "94538 => 94538\n",
      "94085-3010 => 94085\n",
      "94086-6406 => 94086\n",
      "94088-3707 => 94088\n",
      "CUPERTINO => CUPERTINO\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This code will update non 5-digit zipcode.\n",
    "If it is 8/9-digit, only the first 5 digits are kept.\n",
    "If it has the state name in front, only the 5 digits are kept.\n",
    "If it is something else, will not change anything as it might result in error when validating the csv file.\n",
    "'''\n",
    "def update_zipcode(zipcode):\n",
    "    \"\"\"Clean postcode to a uniform format of 5 digit; Return updated postcode\"\"\"\n",
    "    if re.findall(r'^\\d{5}$', zipcode): # 5 digits 02118\n",
    "        valid_zipcode = zipcode\n",
    "        return valid_zipcode\n",
    "    elif re.findall(r'(^\\d{5})-\\d{3}$', zipcode): # 8 digits 02118-029\n",
    "        valid_zipcode = re.findall(r'(^\\d{5})-\\d{3}$', zipcode)[0]\n",
    "        return valid_zipcode\n",
    "    elif re.findall(r'(^\\d{5})-\\d{4}$', zipcode): # 9 digits 02118-0239\n",
    "        valid_zipcode = re.findall(r'(^\\d{5})-\\d{4}$', zipcode)[0]\n",
    "        return valid_zipcode\n",
    "    elif re.findall(r'CA\\s*\\d{5}', zipcode): # with state code CA 02118\n",
    "        valid_zipcode =re.findall(r'\\d{5}', zipcode)[0]  \n",
    "        return valid_zipcode  \n",
    "    else: #return default zipcode to avoid overwriting\n",
    "        return zipcode\n",
    "    \n",
    "def test_zip():\n",
    "    for zips, ways in zip_print.iteritems():\n",
    "        for name in ways:\n",
    "            better_name = update_zipcode(name)\n",
    "            print name, \"=>\", better_name\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_zip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Database into SQL\n",
    "\n",
    "5 cvs files will be created using the schema below which will be then converted into an SQL databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import codecs\n",
    "import cerberus\n",
    "import schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load schema.py\n",
    "'''\n",
    "The schema below for the 5 csv files which will be used to construct a SQL databases\n",
    "'''\n",
    "\n",
    "schema = {\n",
    "    'node': {\n",
    "        'type': 'dict',\n",
    "        'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'lat': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'lon': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'user': {'required': True, 'type': 'string'},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'string'},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "        }\n",
    "    },\n",
    "    'node_tags': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'key': {'required': True, 'type': 'string'},\n",
    "                'value': {'required': True, 'type': 'string'},\n",
    "                'type': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way': {\n",
    "        'type': 'dict',\n",
    "        'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'user': {'required': True, 'type': 'string'},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'string'},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "        }\n",
    "    },\n",
    "    'way_nodes': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'node_id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'position': {'required': True, 'type': 'integer', 'coerce': int}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way_tags': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'key': {'required': True, 'type': 'string'},\n",
    "                'value': {'required': True, 'type': 'string'},\n",
    "                'type': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "5 cvs files are created with the scheme as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The code below is mostly derived from Udacity Lession 13: Case study: OpenStreetMap Data [SQL]\n",
    "https://classroom.udacity.com/nanodegrees/nd002/parts/860b269a-d0b0-4f0c-8f3d-ab08865d43bf/modules/316820862075461/lessons/5436095827/concepts/54908788190923\n",
    "'''\n",
    "OSM_PATH = \"san-jose_california.osm\"\n",
    "OSMFILE = \"san-jose_california.osm\"\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\", \"Circle\", \"Terrace\", \"Way\"]\n",
    "\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Rd.\": \"Road\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Blvd\": \"Boulevard\",\n",
    "            \"Dr\": \"Drive\",\n",
    "            \"Rd\": \"Road\"\n",
    "            }\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "SCHEMA = schema\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "    \n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "    p=0\n",
    "    \n",
    "    if element.tag == 'node':\n",
    "        for i in NODE_FIELDS:\n",
    "            node_attribs[i] = element.attrib[i]\n",
    "        for tag in element.iter(\"tag\"):\n",
    "            node_tags_attribs = {}\n",
    "            temp = LOWER_COLON.search(tag.attrib['k'])\n",
    "            is_p = PROBLEMCHARS.search(tag.attrib['k'])\n",
    "            if is_p:\n",
    "                continue\n",
    "            elif temp:\n",
    "                split_char = temp.group(1)\n",
    "                split_index = tag.attrib['k'].index(split_char)\n",
    "                type1 = temp.group(1)\n",
    "                node_tags_attribs['id'] = element.attrib['id']\n",
    "                node_tags_attribs['key'] = tag.attrib['k'][split_index+2:]\n",
    "                node_tags_attribs['value'] = tag.attrib['v']\n",
    "                node_tags_attribs['type'] = tag.attrib['k'][:split_index+1]\n",
    "                if node_tags_attribs['type'] == \"addr\" and node_tags_attribs['key'] == \"street\":\n",
    "                    # update street name\n",
    "                    node_tags_attribs['value'] = update_name(tag.attrib['v'], mapping) \n",
    "                #elif node_tags_attribs['type'] == \"addr\" and node_tags_attribs['key'] == \"postcode\":\n",
    "                #    # update post code\n",
    "                #    node_tags_attribs['value'] = update_zipcode(tag.attrib['v']) \n",
    "            else:\n",
    "                node_tags_attribs['id'] = element.attrib['id']\n",
    "                node_tags_attribs['key'] = tag.attrib['k']\n",
    "                node_tags_attribs['value'] = tag.attrib['v']\n",
    "                node_tags_attribs['type'] = 'regular'\n",
    "                if node_tags_attribs['type'] == \"addr\" and node_tags_attribs['key'] == \"street\":\n",
    "                    # update street name\n",
    "                    node_tags_attribs['value'] = update_name(tag.attrib['v'], mapping) \n",
    "                #elif node_tags_attribs['type'] == \"addr\" and node_tags_attribs['key'] == \"postcode\":\n",
    "                #    # update post code\n",
    "                #    node_tags_attribs['value'] = update_zipcode(tag.attrib['v']) \n",
    "            tags.append(node_tags_attribs)\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    elif element.tag == 'way':\n",
    "        id = element.attrib['id']\n",
    "        for i in WAY_FIELDS:\n",
    "            way_attribs[i] = element.attrib[i]\n",
    "        for i in element.iter('nd'):\n",
    "            d = {}\n",
    "            d['id'] = id\n",
    "            d['node_id'] = i.attrib['ref']\n",
    "            d['position'] = p\n",
    "            p+=1\n",
    "            way_nodes.append(d)\n",
    "        for c in element.iter('tag'):\n",
    "            temp = LOWER_COLON.search(c.attrib['k'])\n",
    "            is_p = PROBLEMCHARS.search(c.attrib['k'])\n",
    "            e = {}\n",
    "            if is_p:\n",
    "                continue\n",
    "            elif temp:\n",
    "                split_char = temp.group(1)\n",
    "                split_index = c.attrib['k'].index(split_char)\n",
    "                e['id'] = id\n",
    "                e['key'] = c.attrib['k'][split_index+2:]\n",
    "                e['type'] = c.attrib['k'][:split_index+1]\n",
    "                e['value'] = c.attrib['v']\n",
    "                if e['type'] == \"addr\" and e['key'] == \"street\":\n",
    "                    e['value'] = update_name(c.attrib['v'], mapping) \n",
    "                #elif e['type'] == \"addr\" and e['key'] == \"postcode\":\n",
    "                #    e['value'] = update_zipcode(c.attrib['v'])\n",
    "            else:\n",
    "                e['id'] = id\n",
    "                e['key'] = c.attrib['k']\n",
    "                e['type'] = 'regular'\n",
    "                e['value'] =  c.attrib['v']\n",
    "                if e['type'] == \"addr\" and e['key'] == \"street\":\n",
    "                    e['value'] = update_name(c.attrib['v'], mapping) \n",
    "                #elif e['type'] == \"addr\" and e['key'] == \"postcode\":\n",
    "                #    e['value'] = update_zipcode(c.attrib['v'])\n",
    "            tags.append(e)\n",
    "        \n",
    "    return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "        \n",
    "    if element.tag == 'node':\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    elif element.tag == 'way':\n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "    \n",
    "\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "        \n",
    "        raise Exception(message_string.format(field, error_string))\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "    with codecs.open(NODES_PATH, 'wb') as nodes_file, \\\n",
    "        codecs.open(NODE_TAGS_PATH, 'wb') as nodes_tags_file, \\\n",
    "        codecs.open(WAYS_PATH, 'wb') as ways_file, \\\n",
    "        codecs.open(WAY_NODES_PATH, 'wb') as way_nodes_file, \\\n",
    "        codecs.open(WAY_TAGS_PATH, 'wb') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Note: Validation is ~ 10X slower. For the project consider using a small\n",
    "    # sample of the map when validating.\n",
    "    process_map(OSM_PATH, validate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The 5 csv files are then converted into a .db database using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating the database and tables\n",
    "import sqlite3\n",
    "conn = sqlite3.connect('data_wrangling.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.text_factory = str\n",
    "cur = conn.cursor()\n",
    "\n",
    "#Make some fresh tables using executescript()\n",
    "cur.execute('''DROP TABLE IF EXISTS nodes''')\n",
    "cur.execute('''DROP TABLE IF EXISTS nodes_tags''')\n",
    "cur.execute('''DROP TABLE IF EXISTS ways''')\n",
    "cur.execute('''DROP TABLE IF EXISTS ways_tags''')\n",
    "cur.execute('''DROP TABLE IF EXISTS ways_nodes''')\n",
    "\n",
    "\n",
    "cur.execute('''CREATE TABLE nodes (\n",
    "    id INTEGER PRIMARY KEY NOT NULL,\n",
    "    lat REAL,\n",
    "    lon REAL,\n",
    "    user TEXT,\n",
    "    uid INTEGER,\n",
    "    version INTEGER,\n",
    "    changeset INTEGER,\n",
    "    timestamp TEXT)\n",
    "''')\n",
    "\n",
    "with open('nodes.csv','r') as nodes_table: # `with` statement available in 2.5+\n",
    "    # csv.DictReader uses first line in file for column headings by default\n",
    "    dr = csv.DictReader(nodes_table) # comma is default delimiter\n",
    "    to_db = [(i['id'], i['lat'], i['lon'], i['user'], i['uid'], i['version'], i['changeset'], i['timestamp']) for i in dr]\n",
    "\n",
    "cur.executemany(\"INSERT INTO nodes VALUES (?, ?, ?, ?, ?, ?, ?, ?);\", to_db)\n",
    "\n",
    "\n",
    "cur.execute('''CREATE TABLE nodes_tags (\n",
    "    id INTEGER,\n",
    "    key TEXT,\n",
    "    value TEXT,\n",
    "    type TEXT,\n",
    "    FOREIGN KEY (id) REFERENCES nodes(id))\n",
    "''')\n",
    "\n",
    "with open('nodes_tags.csv','r') as nodes_tags_table: # `with` statement available in 2.5+\n",
    "    # csv.DictReader uses first line in file for column headings by default\n",
    "    dr = csv.DictReader(nodes_tags_table) # comma is default delimiter\n",
    "    to_db = [(i['id'], i['key'], i['value'], i['type']) for i in dr]\n",
    "\n",
    "cur.executemany(\"INSERT INTO nodes_tags VALUES (?, ?, ?, ?);\", to_db)\n",
    "\n",
    "cur.execute('''CREATE TABLE ways (\n",
    "    id INTEGER PRIMARY KEY NOT NULL,\n",
    "    user TEXT,\n",
    "    uid INTEGER,\n",
    "    version TEXT,\n",
    "    changeset INTEGER,\n",
    "    timestamp TEXT)\n",
    "''')\n",
    "\n",
    "with open('ways.csv','r') as ways_table: # `with` statement available in 2.5+\n",
    "    # csv.DictReader uses first line in file for column headings by default\n",
    "    dr = csv.DictReader(ways_table) # comma is default delimiter\n",
    "    to_db = [(i['id'], i['user'], i['uid'], i['version'], i['changeset'], i['timestamp']) for i in dr]\n",
    "\n",
    "cur.executemany(\"INSERT INTO ways VALUES (?, ?, ?, ?, ?, ?);\", to_db)\n",
    "\n",
    "cur.execute('''CREATE TABLE ways_tags (\n",
    "    id INTEGER NOT NULL,\n",
    "    key TEXT NOT NULL,\n",
    "    value TEXT NOT NULL,\n",
    "    type TEXT,\n",
    "    FOREIGN KEY (id) REFERENCES ways(id))\n",
    "''')\n",
    "\n",
    "with open('ways_tags.csv','r') as ways_tags_table: # `with` statement available in 2.5+\n",
    "    # csv.DictReader uses first line in file for column headings by default\n",
    "    dr = csv.DictReader(ways_tags_table) # comma is default delimiter\n",
    "    to_db = [(i['id'], i['key'], i['value'], i['type']) for i in dr]\n",
    "\n",
    "cur.executemany(\"INSERT INTO ways_tags VALUES (?, ?, ?, ?);\", to_db)\n",
    "\n",
    "cur.execute('''CREATE TABLE ways_nodes (\n",
    "    id INTEGER NOT NULL,\n",
    "    node_id INTEGER NOT NULL,\n",
    "    position INTEGER NOT NULL,\n",
    "    FOREIGN KEY (id) REFERENCES ways(id),\n",
    "    FOREIGN KEY (node_id) REFERENCES nodes(id))\n",
    "''')\n",
    "\n",
    "with open('ways_nodes.csv','r') as ways_nodes_table: # `with` statement available in 2.5+\n",
    "    # csv.DictReader uses first line in file for column headings by default\n",
    "    dr = csv.DictReader(ways_nodes_table) # comma is default delimiter\n",
    "    to_db = [(i['id'], i['node_id'], i['position']) for i in dr]\n",
    "\n",
    "cur.executemany(\"INSERT INTO ways_nodes VALUES (?, ?, ?);\", to_db)\n",
    "\n",
    "#Save changes\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overviews\n",
    "\n",
    "The queries below provides an overview of the San Jose, CA OpenStreetMap dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The san-jose_california.osm file is 412.959202 MB\n",
      "The nodes.csv file is 160.198493 MB\n",
      "The nodes_tags.csv file is 3.220635 MB\n",
      "The ways.csv file is 15.040047 MB\n",
      "The ways_nodes.csv file is 52.909335 MB\n",
      "The ways_tags.csv file is 23.625255 MB\n",
      "The data_wrangling.sqlite file is 226.950144 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print ('The san-jose_california.osm file is {} MB'.format(os.path.getsize('san-jose_california.osm')/1.0e6))\n",
    "print ('The nodes.csv file is {} MB'.format(os.path.getsize('nodes.csv')/1.0e6))\n",
    "print ('The nodes_tags.csv file is {} MB'.format(os.path.getsize('nodes_tags.csv')/1.0e6))\n",
    "print ('The ways.csv file is {} MB'.format(os.path.getsize('ways.csv')/1.0e6))\n",
    "print ('The ways_nodes.csv file is {} MB'.format(os.path.getsize('ways_nodes.csv')/1.0e6))\n",
    "print ('The ways_tags.csv file is {} MB'.format(os.path.getsize('ways_tags.csv')/1.0e6))\n",
    "print ('The data_wrangling.sqlite file is {} MB'.format(os.path.getsize('data_wrangling.sqlite')/1.0e6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1898718,)\n"
     ]
    }
   ],
   "source": [
    "nodes_count = conn.cursor()\n",
    "nodes_count.execute(\"SELECT COUNT(*) FROM nodes\")\n",
    "\n",
    "nodes_count = nodes_count.fetchall()\n",
    " \n",
    "for row in nodes_count:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250204,)\n"
     ]
    }
   ],
   "source": [
    "ways_count = conn.cursor()\n",
    "ways_count.execute(\"SELECT COUNT(*) FROM ways\")\n",
    "\n",
    "ways_count = ways_count.fetchall()\n",
    " \n",
    "for row in ways_count:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of unique users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1480,)\n"
     ]
    }
   ],
   "source": [
    "unique_user = conn.cursor()\n",
    "unique_user.execute(\"SELECT COUNT(DISTINCT(e.uid)) FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) e\")\n",
    "\n",
    "unique_user = unique_user.fetchall()\n",
    " \n",
    "for row in unique_user:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 5 user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('andygol', 295700)\n",
      "('nmixter', 281943)\n",
      "('mk408', 134593)\n",
      "('Bike Mapper', 94851)\n",
      "('samely', 80727)\n"
     ]
    }
   ],
   "source": [
    "top_user = conn.cursor()\n",
    "top_user.execute(\"SELECT e.user, COUNT(*) as num FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e GROUP BY e.user ORDER BY num DESC LIMIT 5\")\n",
    "\n",
    "top_user = top_user.fetchall()\n",
    " \n",
    "for row in top_user:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 Amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('restaurant', 883)\n",
      "('fast_food', 429)\n",
      "('bench', 320)\n",
      "('cafe', 262)\n",
      "('bicycle_parking', 210)\n",
      "('place_of_worship', 170)\n",
      "('toilets', 163)\n",
      "('school', 137)\n",
      "('fuel', 130)\n",
      "('bank', 129)\n"
     ]
    }
   ],
   "source": [
    "top_amenities = conn.cursor()\n",
    "t = ('amenity',)\n",
    "top_amenities.execute(\"SELECT value, COUNT(*) as num FROM nodes_tags WHERE key=? GROUP BY value ORDER BY num DESC LIMIT 10\", t)\n",
    "\n",
    "top_amenities = top_amenities.fetchall()\n",
    " \n",
    "for row in top_amenities:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Popular Sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fitness', 13)\n",
      "('baseball', 10)\n",
      "('swimming', 10)\n",
      "('yoga', 7)\n",
      "('climbing', 3)\n",
      "('tennis', 3)\n",
      "('basketball', 2)\n",
      "('capoeira', 2)\n",
      "('crossfit', 2)\n",
      "('free_flying', 2)\n"
     ]
    }
   ],
   "source": [
    "top_sports = conn.cursor()\n",
    "t = ('sport',)\n",
    "top_sports.execute(\"SELECT value, COUNT(*) as num FROM nodes_tags WHERE key=? GROUP BY value ORDER BY num DESC LIMIT 10\", t)\n",
    "\n",
    "top_sports = top_sports.fetchall()\n",
    " \n",
    "for row in top_sports:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Tourism-related Amenties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('picnic_site', 168)\n",
      "('information', 75)\n",
      "('hotel', 42)\n",
      "('motel', 25)\n",
      "('artwork', 23)\n",
      "('attraction', 21)\n",
      "('viewpoint', 20)\n",
      "('museum', 12)\n",
      "('camp_site', 4)\n",
      "('gallery', 4)\n",
      "('guest_house', 3)\n",
      "('bus_stop', 1)\n",
      "('caravan_site', 1)\n",
      "('scenic_view', 1)\n",
      "('theme_park', 1)\n",
      "('viewpoint', 1)\n"
     ]
    }
   ],
   "source": [
    "top_tourism = conn.cursor()\n",
    "t = ('tourism', 'tourism_1')\n",
    "top_tourism.execute(\"SELECT value, COUNT(*) as num FROM nodes_tags WHERE key=? GROUP BY value UNION SELECT value, COUNT(*) as num FROM nodes_tags WHERE key=? GROUP BY value ORDER BY num DESC\", t)\n",
    "\n",
    "top_tourism = top_tourism.fetchall()\n",
    " \n",
    "for row in top_tourism:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top City Apprearance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Sunnyvale', 2734)\n",
      "('San Jose', 361)\n",
      "('Santa Clara', 89)\n",
      "('Milpitas', 72)\n",
      "('Los Gatos', 67)\n",
      "('Saratoga', 49)\n",
      "('Morgan Hill', 48)\n",
      "('San Jos\\xc3\\xa9', 46)\n",
      "('Cupertino', 29)\n",
      "('Campbell', 21)\n"
     ]
    }
   ],
   "source": [
    "top_city = conn.cursor()\n",
    "t = ('city',)\n",
    "top_city.execute(\"SELECT value, COUNT(*) as num FROM nodes_tags WHERE key=? GROUP BY value ORDER BY num DESC LIMIT 10\", t)\n",
    "\n",
    "top_city = top_city.fetchall()\n",
    " \n",
    "for row in top_city:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Payment Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('bitcoin', 15)\n",
      "('cash', 10)\n",
      "('credit_cards', 9)\n",
      "('litecoin', 5)\n",
      "('coins', 3)\n",
      "('none', 2)\n",
      "('notes', 2)\n",
      "('visa', 2)\n",
      "('american_express', 1)\n",
      "('diners_club', 1)\n",
      "('discover_card', 1)\n",
      "('dogecoin', 1)\n",
      "('mastercard', 1)\n"
     ]
    }
   ],
   "source": [
    "top_payment = conn.cursor()\n",
    "t = ('payment',)\n",
    "top_payment.execute(\"SELECT key, COUNT(*) as num FROM nodes_tags WHERE type=? GROUP BY key ORDER BY num DESC\", t)\n",
    "\n",
    "top_payment = top_payment.fetchall()\n",
    " \n",
    "for row in top_payment:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the 'nodes_tag' file, there seems to be a lot of inconsistencies or incorrect value.\n",
    "\n",
    "As an open-sourced project, there isn't much restriction placed on data editing. As such, the integrity of the data is easily compromised when there are a lot of users.\n",
    "\n",
    "Few recommended solutions that can be implemented are:\n",
    "- Enforce compulsory columns where users have to fill in all columns in order to submit an entry\n",
    "- Cross-referencing missing data from other open-sourced data from governmental agencies or API\n",
    "- Restructure the schema of the databases so that users are clear what to enter (most useful for address where zipcode or state should have separate columns)\n",
    "- Implement some sort of artificial intelligence to determine potential errors in the entries (such as overabbreviated street types)\n",
    "- Have a bot to update/create entries using data from other sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benefits\n",
    "\n",
    "+ By having a more complete dataset, it can serve as a place to search for places or info for each city\n",
    "+ With proper transportation related ways_tags data, public transportation data can be included\n",
    "+ Cost of manually cleaning or editing errorneous data is high, and the use of a bot or machine learning might help to speed up and bring down the cost in the long run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anticipated Problems\n",
    "\n",
    "- As an open-sourced platform, cost and human reousrces are main issues\n",
    "- Lack of awareness of the existence OSM means it has to be self-sufficient and sustainable in its project taking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "The OpenStreetMap data is a great place for users to contribute to the data. However, if the integrity and completenenss of data are not maintained, it can't compete with other map services such as Google Maps or Apple Maps which has a better user experience and more structure ways of searching for info.\n",
    "\n",
    "With more care taken, OpenStreetMap is capable of being the Wikipedia of maps."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:DAND]",
   "language": "python",
   "name": "conda-env-DAND-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
