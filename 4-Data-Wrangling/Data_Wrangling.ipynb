{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "from collections import defaultdict\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bounds': 1,\n",
      " 'member': 22273,\n",
      " 'nd': 2217224,\n",
      " 'node': 1898718,\n",
      " 'osm': 1,\n",
      " 'relation': 2642,\n",
      " 'tag': 780009,\n",
      " 'way': 250204}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The code below is to find out how many types of tags are there and the number of each tags.\n",
    "It provides an overview of the amount of data in the file.\n",
    "'''\n",
    "\n",
    "def count_tags(filename):\n",
    "    tags = {}\n",
    "    for event, element in ET.iterparse(filename):\n",
    "        if element.tag not in tags.keys():\n",
    "            tags[element.tag] = 1\n",
    "        else:\n",
    "            tags[element.tag] += 1\n",
    "    return tags\n",
    "\n",
    "def test():\n",
    "\n",
    "    tags = count_tags('san-jose_california.osm')\n",
    "    pprint.pprint(tags)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': 522227, 'lower_colon': 235222, 'other': 22560, 'problemchars': 0}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The code below allows you to check the k value for each tag.\n",
    "By classifying the tagss into few categories:\n",
    "1. \"lower\": valid tags containing only lowercase letters\n",
    "2. \"lower_colon\": valid tags with a colon in the names\n",
    "3. \"problemchars\": tags with problematic characters\n",
    "4. \"other\": other tags that don't fall into the 3 categories above\n",
    "'''\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        k = element.attrib['k']\n",
    "        if re.search(lower,k):\n",
    "            keys[\"lower\"] += 1\n",
    "        elif re.search(lower_colon,k):\n",
    "            keys[\"lower_colon\"] += 1\n",
    "        elif re.search(problemchars,k):\n",
    "            keys[\"problemchars\"] += 1\n",
    "        else:\n",
    "            keys[\"other\"] += 1\n",
    "    return keys\n",
    "\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "    return keys\n",
    "\n",
    "def test():\n",
    "    keys = process_map('san-jose_california.osm')\n",
    "    pprint.pprint(keys)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1492\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The code below is to find out how many unique users are contributing to San Jose, CA map.\n",
    "'''\n",
    "def get_user(element):\n",
    "    if element.get(\"uid\"):\n",
    "        uid = element.attrib[\"uid\"]\n",
    "        return uid\n",
    "    else:\n",
    "        return none\n",
    "\n",
    "def process_map(filename):\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        if element.get(\"uid\"):\n",
    "            users.add(element.attrib[\"uid\"])\n",
    "    return users\n",
    "\n",
    "def test():\n",
    "    users = process_map('san-jose_california.osm')\n",
    "    print len(users)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0.1': set(['Ala 680 PM 0.1']),\n",
      " '1': set(['Prospect Rd #1', 'Stewart Drive Suite #1']),\n",
      " '114': set(['West Evelyn Avenue Suite #114']),\n",
      " '201': set(['Great America Pkwy Ste 201']),\n",
      " '4A': set(['Saratoga Avenue Bldg 4A']),\n",
      " '6': set(['Martin Avenue #6', 'Pruneridge Ave #6']),\n",
      " '7.1': set(['Hwy 17 PM 7.1']),\n",
      " '81': set(['Concourse Dr #81']),\n",
      " 'Alameda': set(['The Alameda']),\n",
      " 'Alley': set(['Fountain Alley']),\n",
      " 'Ave': set(['1425 E Dunne Ave',\n",
      "             'Blake Ave',\n",
      "             'Cabrillo Ave',\n",
      "             'Cherry Ave',\n",
      "             'E Duane Ave',\n",
      "             'Foxworthy Ave',\n",
      "             'Greenbriar Ave',\n",
      "             'Hillsdale Ave',\n",
      "             'Hollenbeck Ave',\n",
      "             'Meridian Ave',\n",
      "             'N Blaney Ave',\n",
      "             'Saratoga Ave',\n",
      "             'Seaboard Ave',\n",
      "             'The Alameda Ave',\n",
      "             'W Washington Ave',\n",
      "             'Walsh Ave',\n",
      "             'Westfield Ave']),\n",
      " 'Barcelona': set(['Calle de Barcelona']),\n",
      " 'Bascom': set(['S. Bascom']),\n",
      " 'Bellomy': set(['Bellomy']),\n",
      " 'Blvd': set(['Los Gatos Blvd',\n",
      "              'McCarthy Blvd',\n",
      "              'Mission College Blvd',\n",
      "              'N McCarthy Blvd',\n",
      "              'Palm Valley Blvd',\n",
      "              'Santa Teresa Blvd',\n",
      "              'Stevens Creek Blvd']),\n",
      " 'Blvd.': set(['Los Gatos Blvd.']),\n",
      " 'Boulvevard': set(['Los Gatos Boulvevard']),\n",
      " 'Broadway': set(['Broadway']),\n",
      " 'CA': set(['Zanker Rd., San Jose, CA', 'Zanker Road, San Jose, CA']),\n",
      " 'Cir': set(['Celadon Cir']),\n",
      " 'Ct': set(['Perivale Ct']),\n",
      " 'Dr': set(['1350 S Park Victoria Dr',\n",
      "            '1490 S Park Victoria Dr',\n",
      "            'Fountain Oaks Dr',\n",
      "            'Linwood Dr',\n",
      "            'Minto Dr',\n",
      "            'Oakmead Village Dr',\n",
      "            'Samaritan Dr']),\n",
      " 'East': set(['Park Circle East', 'Rio Robles East', 'Vanderbilt Court East']),\n",
      " 'Esquela': set(['Camina Esquela']),\n",
      " 'Expressway': set(['Almaden Expressway',\n",
      "                    'Central Expressway',\n",
      "                    'East Capitol Expressway',\n",
      "                    'Lawrence Expressway',\n",
      "                    'Montague Expressway',\n",
      "                    'San Tomas Expressway',\n",
      "                    'Southwest Expressway',\n",
      "                    'West Capitol Expressway']),\n",
      " 'Flores': set(['Terreno De Flores']),\n",
      " 'Franklin': set(['Franklin']),\n",
      " 'Hamilton': set(['Mount Hamilton']),\n",
      " 'Highway': set(['Monterey Highway',\n",
      "                 'Old Bayshore Highway',\n",
      "                 'Old Santa Cruz Highway']),\n",
      " 'Hill': set(['Blossom Hill']),\n",
      " 'Hwy': set(['Monterey Hwy']),\n",
      " 'Ln': set(['Barber Ln', 'Branham Ln', 'Gaundabert Ln']),\n",
      " 'Loop': set(['Infinite Loop', 'Village View Loop']),\n",
      " 'Luna': set(['Calle de Luna']),\n",
      " 'Madrid': set(['Corte de Madrid']),\n",
      " 'Mall': set(['Franklin Mall']),\n",
      " 'Marino': set(['Via San Marino']),\n",
      " u'Monta\\xf1a': set([u'Vista Monta\\xf1a']),\n",
      " 'Napoli': set(['Via Napoli']),\n",
      " 'Oaks': set(['North Fair Oaks']),\n",
      " 'Oro': set(['Via del Oro']),\n",
      " 'Palamos': set(['Via Palamos']),\n",
      " 'Paviso': set(['Via Paviso']),\n",
      " 'Plaza': set(['Portal Plaza', 'Rivermark Plaza']),\n",
      " 'Portofino': set(['Via Portofino']),\n",
      " 'Presada': set(['Paseo Presada']),\n",
      " 'Rd': set(['Berryessa Rd',\n",
      "            'Homestead Rd',\n",
      "            'Mt Hamilton Rd',\n",
      "            'Mt. Hamilton Rd',\n",
      "            'Quimby Rd',\n",
      "            'San Antonio Valley Rd',\n",
      "            'Saratoga Los Gatos Rd',\n",
      "            'Silver Creek Valley Rd',\n",
      "            'Wolfe Rd']),\n",
      " 'Real': set(['E El Camino Real',\n",
      "              'East El Camino Real',\n",
      "              'El Camino Real',\n",
      "              'West El Camino Real']),\n",
      " 'Row': set(['Santana Row']),\n",
      " 'Saratoga': set(['El Paseo de Saratoga']),\n",
      " 'Seville': set(['Corte de Seville']),\n",
      " 'Sorrento': set(['Via Sorrento']),\n",
      " 'St': set(['Casa Verde St', 'Monroe St', 'N 5th St']),\n",
      " 'Volante': set(['Via Volante']),\n",
      " 'Walk': set(['Paseo de San Antonio Walk']),\n",
      " 'West': set(['Park Circle West', 'Vanderbilt Court West']),\n",
      " 'Winchester': set(['Winchester']),\n",
      " 'ave': set(['wilcox ave']),\n",
      " 'court': set(['Cortona court']),\n",
      " 'robles': set(['rio robles']),\n",
      " 'street': set(['N 1st street']),\n",
      " 'yes': set(['yes'])}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The code below lists out all the street types not in the expected list.\n",
    "'''\n",
    "OSMFILE = \"san-jose_california.osm\"\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\", \"Circle\", \"Terrace\", \"Way\"]\n",
    "\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n",
    "st_types = audit(OSMFILE)\n",
    "\n",
    "def test():    \n",
    "    pprint.pprint(dict(st_types))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Martin Avenue #6 => Martin Avenue #6\n",
      "Pruneridge Ave #6 => Pruneridge Ave #6\n",
      "Concourse Dr #81 => Concourse Dr #81\n",
      "Winchester => Winchester\n",
      "Gaundabert Ln => Gaundabert Ln\n",
      "Barber Ln => Barber Ln\n",
      "Branham Ln => Branham Ln\n",
      "Park Circle West => Park Circle West\n",
      "Vanderbilt Court West => Vanderbilt Court West\n",
      "Wolfe Rd => Wolfe Road\n",
      "Mt Hamilton Rd => Mt Hamilton Road\n",
      "Berryessa Rd => Berryessa Road\n",
      "Saratoga Los Gatos Rd => Saratoga Los Gatos Road\n",
      "Quimby Rd => Quimby Road\n",
      "San Antonio Valley Rd => San Antonio Valley Road\n",
      "Homestead Rd => Homestead Road\n",
      "Mt. Hamilton Rd => Mt. Hamilton Road\n",
      "Silver Creek Valley Rd => Silver Creek Valley Road\n",
      "West Evelyn Avenue Suite #114 => West Evelyn Avenue Suite #114\n",
      "Hwy 17 PM 7.1 => Hwy 17 PM 7.1\n",
      "Blossom Hill => Blossom Hill\n",
      "wilcox ave => wilcox ave\n",
      "North Fair Oaks => North Fair Oaks\n",
      "Vanderbilt Court East => Vanderbilt Court East\n",
      "Park Circle East => Park Circle East\n",
      "Rio Robles East => Rio Robles East\n",
      "The Alameda => The Alameda\n",
      "yes => yes\n",
      "Monterey Highway => Monterey Highway\n",
      "Old Santa Cruz Highway => Old Santa Cruz Highway\n",
      "Old Bayshore Highway => Old Bayshore Highway\n",
      "El Camino Real => El Camino Real\n",
      "E El Camino Real => E El Camino Real\n",
      "West El Camino Real => West El Camino Real\n",
      "East El Camino Real => East El Camino Real\n",
      "San Tomas Expressway => San Tomas Expressway\n",
      "East Capitol Expressway => East Capitol Expressway\n",
      "Montague Expressway => Montague Expressway\n",
      "West Capitol Expressway => West Capitol Expressway\n",
      "Central Expressway => Central Expressway\n",
      "Almaden Expressway => Almaden Expressway\n",
      "Lawrence Expressway => Lawrence Expressway\n",
      "Southwest Expressway => Southwest Expressway\n",
      "Cortona court => Cortona court\n",
      "Via Paviso => Via Paviso\n",
      "Vista Montaña => Vista Montaña\n",
      "Stewart Drive Suite #1 => Stewart Drive Suite #1\n",
      "Prospect Rd #1 => Prospect Rd #1\n",
      "Via del Oro => Via del Oro\n",
      "Terreno De Flores => Terreno De Flores\n",
      "Mount Hamilton => Mount Hamilton\n",
      "Via San Marino => Via San Marino\n",
      "Monterey Hwy => Monterey Hwy\n",
      "Via Volante => Via Volante\n",
      "S. Bascom => S. Bascom\n",
      "Oakmead Village Dr => Oakmead Village Drive\n",
      "Fountain Oaks Dr => Fountain Oaks Drive\n",
      "Minto Dr => Minto Drive\n",
      "1350 S Park Victoria Dr => 1350 S Park Victoria Drive\n",
      "Linwood Dr => Linwood Drive\n",
      "1490 S Park Victoria Dr => 1490 S Park Victoria Drive\n",
      "Samaritan Dr => Samaritan Drive\n",
      "Great America Pkwy Ste 201 => Great America Pkwy Ste 201\n",
      "Camina Esquela => Camina Esquela\n",
      "Ala 680 PM 0.1 => Ala 680 PM 0.1\n",
      "Bellomy => Bellomy\n",
      "Via Napoli => Via Napoli\n",
      "El Paseo de Saratoga => El Paseo de Saratoga\n",
      "Zanker Rd., San Jose, CA => Zanker Rd., San Jose, CA\n",
      "Zanker Road, San Jose, CA => Zanker Road, San Jose, CA\n",
      "Portal Plaza => Portal Plaza\n",
      "Rivermark Plaza => Rivermark Plaza\n",
      "Calle de Barcelona => Calle de Barcelona\n",
      "N 5th St => N 5th Street\n",
      "Monroe St => Monroe Street\n",
      "Casa Verde St => Casa Verde Street\n",
      "Celadon Cir => Celadon Cir\n",
      "Franklin Mall => Franklin Mall\n",
      "Franklin => Franklin\n",
      "Broadway => Broadway\n",
      "Via Palamos => Via Palamos\n",
      "Corte de Seville => Corte de Seville\n",
      "Paseo Presada => Paseo Presada\n",
      "Village View Loop => Village View Loop\n",
      "Infinite Loop => Infinite Loop\n",
      "Saratoga Avenue Bldg 4A => Saratoga Avenue Bldg 4A\n",
      "Via Sorrento => Via Sorrento\n",
      "Los Gatos Boulvevard => Los Gatos Boulvevard\n",
      "Corte de Madrid => Corte de Madrid\n",
      "Via Portofino => Via Portofino\n",
      "Fountain Alley => Fountain Alley\n",
      "Paseo de San Antonio Walk => Paseo de San Antonio Walk\n",
      "Calle de Luna => Calle de Luna\n",
      "N 1st street => N 1st street\n",
      "rio robles => rio robles\n",
      "Los Gatos Blvd => Los Gatos Boulevard\n",
      "Mission College Blvd => Mission College Boulevard\n",
      "Stevens Creek Blvd => Stevens Creek Boulevard\n",
      "Santa Teresa Blvd => Santa Teresa Boulevard\n",
      "Palm Valley Blvd => Palm Valley Boulevard\n",
      "N McCarthy Blvd => N McCarthy Boulevard\n",
      "McCarthy Blvd => McCarthy Boulevard\n",
      "Cherry Ave => Cherry Avenue\n",
      "Saratoga Ave => Saratoga Avenue\n",
      "Greenbriar Ave => Greenbriar Avenue\n",
      "Blake Ave => Blake Avenue\n",
      "Foxworthy Ave => Foxworthy Avenue\n",
      "Hillsdale Ave => Hillsdale Avenue\n",
      "N Blaney Ave => N Blaney Avenue\n",
      "Meridian Ave => Meridian Avenue\n",
      "Westfield Ave => Westfield Avenue\n",
      "The Alameda Ave => The Alameda Avenue\n",
      "Seaboard Ave => Seaboard Avenue\n",
      "Walsh Ave => Walsh Avenue\n",
      "E Duane Ave => E Duane Avenue\n",
      "W Washington Ave => W Washington Avenue\n",
      "1425 E Dunne Ave => 1425 E Dunne Avenue\n",
      "Cabrillo Ave => Cabrillo Avenue\n",
      "Hollenbeck Ave => Hollenbeck Avenue\n",
      "Santana Row => Santana Row\n",
      "Los Gatos Blvd. => Los Gatos Blvd.\n",
      "Perivale Ct => Perivale Ct\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The code below updates the unexpected street types listed in the mapping list\n",
    "while keeping others unchanged.\n",
    "'''\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Rd.\": \"Road\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Blvd\": \"Boulevard\",\n",
    "            \"Dr\": \"Drive\",\n",
    "            \"Rd\": \"Road\"\n",
    "            }\n",
    "\n",
    "def update_name(name, mapping):\n",
    "    m = street_type_re.search(name)\n",
    "    if m.group() not in expected:\n",
    "        if m.group() in mapping.keys():\n",
    "            name = re.sub(m.group(), mapping[m.group()], name)\n",
    "    return name\n",
    "\n",
    "def test():\n",
    "    for st_type, ways in st_types.iteritems():\n",
    "        for name in ways:\n",
    "            better_name = update_name(name, mapping)\n",
    "            print name, \"=>\", better_name\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import codecs\n",
    "import cerberus\n",
    "import schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load schema.py\n",
    "# Note: The schema is stored in a .py file in order to take advantage of the\n",
    "# int() and float() type coercion functions. Otherwise it could easily stored as\n",
    "# as JSON or another serialized format.\n",
    "\n",
    "schema = {\n",
    "    'node': {\n",
    "        'type': 'dict',\n",
    "        'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'lat': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'lon': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'user': {'required': True, 'type': 'string'},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'string'},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "        }\n",
    "    },\n",
    "    'node_tags': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'key': {'required': True, 'type': 'string'},\n",
    "                'value': {'required': True, 'type': 'string'},\n",
    "                'type': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way': {\n",
    "        'type': 'dict',\n",
    "        'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'user': {'required': True, 'type': 'string'},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'string'},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "        }\n",
    "    },\n",
    "    'way_nodes': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'node_id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'position': {'required': True, 'type': 'integer', 'coerce': int}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way_tags': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'key': {'required': True, 'type': 'string'},\n",
    "                'value': {'required': True, 'type': 'string'},\n",
    "                'type': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "'''\n",
    "OSM_PATH = \"san-jose_california.osm\"\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "SCHEMA = schema\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "    p=0\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    if element.tag == 'node':\n",
    "        for i in NODE_FIELDS:\n",
    "            node_attribs[i] = element.attrib[i]\n",
    "        for tag in element.iter(\"tag\"):\n",
    "            node_tags_attribs = {}\n",
    "            temp = LOWER_COLON.search(tag.attrib['k'])\n",
    "            is_p = PROBLEMCHARS.search(tag.attrib['k'])\n",
    "            if is_p:\n",
    "                continue\n",
    "            elif temp:\n",
    "                split_char = temp.group(1)\n",
    "                split_index = tag.attrib['k'].index(split_char)\n",
    "                type1 = temp.group(1)\n",
    "                node_tags_attribs['id'] = element.attrib['id']\n",
    "                node_tags_attribs['key'] = tag.attrib['k'][split_index+2:]\n",
    "                node_tags_attribs['value'] = tag.attrib['v']\n",
    "                node_tags_attribs['type'] = tag.attrib['k'][:split_index+1]\n",
    "            else:\n",
    "                node_tags_attribs['id'] = element.attrib['id']\n",
    "                node_tags_attribs['key'] = tag.attrib['k']\n",
    "                node_tags_attribs['value'] = tag.attrib['v']\n",
    "                node_tags_attribs['type'] = 'regular'\n",
    "            tags.append(node_tags_attribs)\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    elif element.tag == 'way':\n",
    "        id = element.attrib['id']\n",
    "        for i in WAY_FIELDS:\n",
    "            way_attribs[i] = element.attrib[i]\n",
    "        for i in element.iter('nd'):\n",
    "            d = {}\n",
    "            d['id'] = id\n",
    "            d['node_id'] = i.attrib['ref']\n",
    "            d['position'] = p\n",
    "            p+=1\n",
    "            way_nodes.append(d)\n",
    "        for c in element.iter('tag'):\n",
    "            temp = LOWER_COLON.search(c.attrib['k'])\n",
    "            is_p = PROBLEMCHARS.search(c.attrib['k'])\n",
    "            e = {}\n",
    "            if is_p:\n",
    "                continue\n",
    "            elif temp:\n",
    "                split_char = temp.group(1)\n",
    "                split_index = c.attrib['k'].index(split_char)\n",
    "                e['id'] = id\n",
    "                e['key'] = c.attrib['k'][split_index+2:]\n",
    "                e['type'] = c.attrib['k'][:split_index+1]\n",
    "                e['value'] = c.attrib['v']\n",
    "            else:\n",
    "                e['id'] = id\n",
    "                e['key'] = c.attrib['k']\n",
    "                e['type'] = 'regular'\n",
    "                e['value'] =  c.attrib['v']\n",
    "            tags.append(e)\n",
    "        \n",
    "    return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "        \n",
    "    if element.tag == 'node':\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    elif element.tag == 'way':\n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "    \n",
    "\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "        \n",
    "        raise Exception(message_string.format(field, error_string))\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "        codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "        codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "        codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "        codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Note: Validation is ~ 10X slower. For the project consider using a small\n",
    "    # sample of the map when validating.\n",
    "    process_map(OSM_PATH, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating the database and tables\n",
    "import sqlite3\n",
    "conn = sqlite3.connect('data_wrangling.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.text_factory = str\n",
    "cur = conn.cursor()\n",
    "\n",
    "#Make some fresh tables using executescript()\n",
    "cur.execute('''DROP TABLE IF EXISTS nodes''')\n",
    "cur.execute('''DROP TABLE IF EXISTS nodes_tags''')\n",
    "cur.execute('''DROP TABLE IF EXISTS ways''')\n",
    "cur.execute('''DROP TABLE IF EXISTS ways_tags''')\n",
    "cur.execute('''DROP TABLE IF EXISTS ways_nodes''')\n",
    "\n",
    "\n",
    "cur.execute('''CREATE TABLE nodes (\n",
    "    id INTEGER PRIMARY KEY NOT NULL,\n",
    "    lat REAL,\n",
    "    lon REAL,\n",
    "    user TEXT,\n",
    "    uid INTEGER,\n",
    "    version INTEGER,\n",
    "    changeset INTEGER,\n",
    "    timestamp TEXT)\n",
    "''')\n",
    "\n",
    "with open('nodes.csv','r') as nodes_table: # `with` statement available in 2.5+\n",
    "    # csv.DictReader uses first line in file for column headings by default\n",
    "    dr = csv.DictReader(nodes_table) # comma is default delimiter\n",
    "    to_db = [(i['id'], i['lat'], i['lon'], i['user'], i['uid'], i['version'], i['changeset'], i['timestamp']) for i in dr]\n",
    "\n",
    "cur.executemany(\"INSERT INTO nodes VALUES (?, ?, ?, ?, ?, ?, ?, ?);\", to_db)\n",
    "\n",
    "\n",
    "cur.execute('''CREATE TABLE nodes_tags (\n",
    "    id INTEGER,\n",
    "    key TEXT,\n",
    "    value TEXT,\n",
    "    type TEXT,\n",
    "    FOREIGN KEY (id) REFERENCES nodes(id))\n",
    "''')\n",
    "\n",
    "with open('nodes_tags.csv','r') as nodes_tags_table: # `with` statement available in 2.5+\n",
    "    # csv.DictReader uses first line in file for column headings by default\n",
    "    dr = csv.DictReader(nodes_tags_table) # comma is default delimiter\n",
    "    to_db = [(i['id'], i['key'], i['value'], i['type']) for i in dr]\n",
    "\n",
    "cur.executemany(\"INSERT INTO nodes_tags VALUES (?, ?, ?, ?);\", to_db)\n",
    "\n",
    "cur.execute('''CREATE TABLE ways (\n",
    "    id INTEGER PRIMARY KEY NOT NULL,\n",
    "    user TEXT,\n",
    "    uid INTEGER,\n",
    "    version TEXT,\n",
    "    changeset INTEGER,\n",
    "    timestamp TEXT)\n",
    "''')\n",
    "\n",
    "with open('ways.csv','r') as ways_table: # `with` statement available in 2.5+\n",
    "    # csv.DictReader uses first line in file for column headings by default\n",
    "    dr = csv.DictReader(ways_table) # comma is default delimiter\n",
    "    to_db = [(i['id'], i['user'], i['uid'], i['version'], i['changeset'], i['timestamp']) for i in dr]\n",
    "\n",
    "cur.executemany(\"INSERT INTO ways VALUES (?, ?, ?, ?, ?, ?);\", to_db)\n",
    "\n",
    "cur.execute('''CREATE TABLE ways_tags (\n",
    "    id INTEGER NOT NULL,\n",
    "    key TEXT NOT NULL,\n",
    "    value TEXT NOT NULL,\n",
    "    type TEXT,\n",
    "    FOREIGN KEY (id) REFERENCES ways(id))\n",
    "''')\n",
    "\n",
    "with open('ways_tags.csv','r') as ways_tags_table: # `with` statement available in 2.5+\n",
    "    # csv.DictReader uses first line in file for column headings by default\n",
    "    dr = csv.DictReader(ways_tags_table) # comma is default delimiter\n",
    "    to_db = [(i['id'], i['key'], i['value'], i['type']) for i in dr]\n",
    "\n",
    "cur.executemany(\"INSERT INTO ways_tags VALUES (?, ?, ?, ?);\", to_db)\n",
    "\n",
    "cur.execute('''CREATE TABLE ways_nodes (\n",
    "    id INTEGER NOT NULL,\n",
    "    node_id INTEGER NOT NULL,\n",
    "    position INTEGER NOT NULL,\n",
    "    FOREIGN KEY (id) REFERENCES ways(id),\n",
    "    FOREIGN KEY (node_id) REFERENCES nodes(id))\n",
    "''')\n",
    "\n",
    "with open('ways_nodes.csv','r') as ways_nodes_table: # `with` statement available in 2.5+\n",
    "    # csv.DictReader uses first line in file for column headings by default\n",
    "    dr = csv.DictReader(ways_nodes_table) # comma is default delimiter\n",
    "    to_db = [(i['id'], i['node_id'], i['position']) for i in dr]\n",
    "\n",
    "cur.executemany(\"INSERT INTO ways_nodes VALUES (?, ?, ?);\", to_db)\n",
    "\n",
    "#Save changes\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:DAND]",
   "language": "python",
   "name": "conda-env-DAND-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
